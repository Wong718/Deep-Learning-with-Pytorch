# Day6

### Torchvision

**torchvision简介**

**torchvision.datasets**

**torchvision.transforms**

```python
#图像数据处理与数据增强
from torchvision import transforms
data_transform = transforms.Compose([
    transforms.ToPILImage(),   # 这一步取决于后续的数据读取方式，如果使用内置数据集则不需要
    transforms.Resize(image_size),
    transforms.ToTensor()
])
```

**torchvision.models**

预训练的模型

- classification
- semantic segmentation：语义分割
- Object Detection，instance Segmentation and Keypoint Detection
- video classification

**torchvision.io**

视频、图片和文件的 IO 操作的功能

**torchvision.ops**

许多计算机视觉的特定操作

**torchvision.utils**

torchvision.utils 为我们提供了一些可视化的方法，可以帮助我们将若干张图片拼接在一起、可视化检测和分割的效果

### PyTorchVideo

**Model zoo 和 benchmark**

**使用 PyTorchVideo model zoo**

### torchtext

PyTorch官方用于自然语言处理（NLP）的工具包torchtext

**torchtext的主要组成部分**

- 数据处理工具 torchtext.data.functional、torchtext.data.utils
- 数据集 torchtext.data.datasets
- 词表工具 torchtext.vocab
- 评测指标 torchtext.metrics

**构建数据集**

- **Field及其使用**
    - Field是torchtext中定义数据类型以及转换为张量的指令
        
        ```python
        tokenize = lambda x: x.split()
        TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, fix_length=200)
        LABEL = data.Field(sequential=False, use_vocab=False)
        ```
        
        - sequential设置数据是否是顺序表示的；
        - tokenize用于设置将字符串标记为顺序实例的函数
        - lower设置是否将字符串全部转为小写；
        - fix_length设置此字段所有实例都将填充到一个固定的长度，方便后续处理；
        - use_vocab设置是否引入Vocab object，如果为False，则需要保证之后输入field中的data都是numerical的
        
        ```python
        from torchtext import data
        def get_dataset(csv_data, text_field, label_field, test=False):
            fields = [("id", None), # we won't be needing the id, so we pass in None as the field
                         ("comment_text", text_field), ("toxic", label_field)]       
            examples = []
        
            if test:
                # 如果为测试集，则不加载label
                for text in tqdm(csv_data['comment_text']):
                    examples.append(data.Example.fromlist([None, text, None], fields))
            else:
                for text, label in tqdm(zip(csv_data['comment_text'], csv_data['toxic'])):
                    examples.append(data.Example.fromlist([None, text, label], fields))
            return examples, fields
        ```
        
        ```python
        train_data = pd.read_csv('train_toxic_comments.csv')
        valid_data = pd.read_csv('valid_toxic_comments.csv')
        test_data = pd.read_csv("test_toxic_comments.csv")
        TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True)
        LABEL = data.Field(sequential=False, use_vocab=False)
        
        # 得到构建Dataset所需的examples和fields
        train_examples, train_fields = get_dataset(train_data, TEXT, LABEL)
        valid_examples, valid_fields = get_dataset(valid_data, TEXT, LABEL)
        test_examples, test_fields = get_dataset(test_data, TEXT, None, test=True)
        # 构建Dataset数据集
        train = data.Dataset(train_examples, train_fields)
        valid = data.Dataset(valid_examples, valid_fields)
        test = data.Dataset(test_examples, test_fields)
        ```
        
- **词汇表（vocab）**
    - 将字符串形式的词语（word）转变为数字形式的向量表示（embedding）是非常重要的一步，被称为Word Embedding
    
    ```python
    TEXT.build_vocab(train)
    ```
    
- **数据迭代器**
    
    ```python
    # 若只针对训练集构造迭代器
    # train_iter = data.BucketIterator(dataset=train, batch_size=8, shuffle=True, sort_within_batch=False, repeat=False)
    
    # 同时对训练集和验证集进行迭代器的构建
    train_iter, val_iter = BucketIterator.splits(
            (train, valid), # 构建数据集所需的数据集
            batch_sizes=(8, 8),
            device=-1, # 如果使用gpu，此处将-1更换为GPU的编号
            sort_key=lambda x: len(x.comment_text), # the BucketIterator needs to be told what function it should use to group the data.
            sort_within_batch=False
    )
    
    test_iter = Iterator(test, batch_size=8, device=-1, sort=False, sort_within_batch=False)
    ```
    
- **测评指标**
    
    ```python
    from torchtext.data.metricsimport bleu_score
    candidate_corpus=[['My', 'full', 'pytorch', 'test'],['Another', 'Sentence']]references_corpus=[[['My', 'full', 'pytorch', 'test'],['Completely', 'Different']],[['No', 'Match']]]bleu_score(candidate_corpus, references_corpus)
    ```
    
- 模型主要通过torch.nn中的模块来实现，比如torch.nn.LSTM、torch.nn.RNN等。

### Transform实战

```python
from PIL import Image
from torchvision import transforms
import matplotlib.pyplot as plt
%matplotlib inline
# 加载原始图片
img = Image.open("./lenna.jpg") 
print(img.size)
plt.imshow(img)
```

```python
# 对给定图片进行沿中心切割
# 对图片沿中心放大切割，超出图片大小的部分填0
img_centercrop1 = transforms.CenterCrop((500,500))(img)
print(img_centercrop1.size)
# 对图片沿中心缩小切割，超出期望大小的部分剔除
img_centercrop2 = transforms.CenterCrop((224,224))(img)
print(img_centercrop2.size)
plt.subplot(1,3,1),plt.imshow(img),plt.title("Original")
plt.subplot(1,3,2),plt.imshow(img_centercrop1),plt.title("500 * 500")
plt.subplot(1,3,3),plt.imshow(img_centercrop2),plt.title("224 * 224")
plt.show()
```

```python
# 对图片的亮度，对比度，饱和度，色调进行改变
img_CJ = transforms.ColorJitter(brightness=1,contrast=0.5,saturation=0.5,hue=0.5)(img)
print(img_CJ.size)
plt.imshow(img_CJ)
```

```python
img_grey_c3 = transforms.Grayscale(num_output_channels=3)(img)
img_grey_c1 = transforms.Grayscale(num_output_channels=1)(img)
plt.subplot(1,2,1),plt.imshow(img_grey_c3),plt.title("channels=3")
plt.subplot(1,2,2),plt.imshow(img_grey_c1),plt.title("channels=1")
plt.show()
```

```python
# 等比缩放
img_resize = transforms.Resize(224)(img)
print(img_resize.size)
plt.imshow(img_resize)
```

```python
# 随机裁剪成指定大小
# 设立随机种子
import torch
torch.manual_seed(31)
# 随机裁剪
img_randowm_crop1 = transforms.RandomCrop(224)(img)
img_randowm_crop2 = transforms.RandomCrop(224)(img)
print(img_randowm_crop1.size)
plt.subplot(1,2,1),plt.imshow(img_randowm_crop1)
plt.subplot(1,2,2),plt.imshow(img_randowm_crop2)
plt.show()
```

```python
# 随机左右旋转
# 设立随机种子，可能不旋转
import torch
torch.manual_seed(31)

img_random_H = transforms.RandomHorizontalFlip()(img)
print(img_random_H.size)
plt.imshow(img_random_H)
```

```python
# 随机垂直方向旋转
img_random_V = transforms.RandomVerticalFlip()(img)
print(img_random_V.size)
plt.imshow(img_random_V)
```

```python
# 随机裁剪成指定大小
img_random_resizecrop = transforms.RandomResizedCrop(224,scale=(0.5,0.5))(img)
print(img_random_resizecrop.size)
plt.imshow(img_random_resizecrop)
```

```python
# 对一张图片的操作可能是多种的，我们使用transforms.Compose()将他们组装起来
transformer = transforms.Compose([
    transforms.Resize(256),
    transforms.transforms.RandomResizedCrop((224), scale = (0.5,1.0)),
    transforms.RandomVerticalFlip(),
])
img_transform = transformer(img)
plt.imshow(img_transform)
```

```python
# 对一张图片的操作可能是多种的，我们使用transforms.Compose()将他们组装起来
transformer = transforms.Compose([
    transforms.Resize(256),
    transforms.transforms.RandomResizedCrop((224), scale = (0.5,1.0)),
    transforms.RandomVerticalFlip(),
])
img_transform = transformer(img)
plt.imshow(img_transform)
```

## PyTorch的模型部署

**ONNX和ONNX Runtime**

ONNX可以看作深度学习框架和部署端的桥梁，就像编译器的中间语言一样

**ONNX Runtime**
 是由微软维护的一个跨平台机器学习推理加速器，它直接对接ONNX，可以直接读取.onnx文件并实现推理，不需要再把 .onnx 格式的文件转换成其他格式的文件

**代码实战**

**定义超分辨模型**

```python
# 导入相关包
import io
import numpy as np
from torch import nn
import torch.utils.model_zoo as model_zoo
import torch.onnx
import torch.nn as nn
import torch.nn.init as init

# 定义超分辨网络
class SuperResolutionNet(nn.Module):
    def __init__(self, upscale_factor, inplace=False):
        super(SuperResolutionNet, self).__init__()

        self.relu = nn.ReLU(inplace=inplace)
        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))
        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))
        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))
        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))
        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)

        self._initialize_weights()

    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.relu(self.conv3(x))
        x = self.pixel_shuffle(self.conv4(x))
        return x
    
	# 模型初始化
    def _initialize_weights(self):
        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))
        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))
        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))
        init.orthogonal_(self.conv4.weight)

# 实例化模型
torch_model = SuperResolutionNet(upscale_factor=3)
```

**模型导出为ONNX格式**

```python
model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'
batch_size = 1    # just a random number
# 加载预训练得到权重
map_location = lambda storage, loc: storage
if torch.cuda.is_available():
    map_location = None
torch_model.load_state_dict(model_zoo.load_url(model_url, map_location=map_location))

# 将模型设置为推理模式
torch_model.eval()
# Input to the model
x = torch.randn(batch_size, 1, 224, 224, requires_grad=True)
torch_out = torch_model(x)

# 导出模型
torch.onnx.export(torch_model,               # model being run
                  x,             # model input (or a tuple for multiple inputs)
                  "super_resolution.onnx",   # where to save the model (can be a file or file-like object)
                  export_params=True,        # store the trained parameter weights inside the model file
                  opset_version=10,   # the ONNX version to export the model to
                  do_constant_folding=True,  # whether to execute constant folding for optimization
                  input_names = ['input'],   # the model's input names
                  output_names = ['output'], # the model's output names
                  # variable length axes
                  dynamic_axes={'input' : {0 : 'batch_size'},    
                                'output' : {0 : 'batch_size'}})
```

**检验ONNX模型**

```python
import onnx
# 我们可以使用异常处理的方法进行检验
try:
    # 当我们的模型不可用时，将会报出异常
    onnx.checker.check_model("super_resolution.onnx")
except onnx.checker.ValidationError as e:
    print("The model is invalid: %s"%e)
else:
    # 模型可用时，将不会报出异常，并会输出“The model is valid!”
    print("The model is valid!")
```

**使用ONNX Runtime进行推理**

```python
import onnxruntime

ort_session = onnxruntime.InferenceSession("super_resolution.onnx")

# 将张量转化为ndarray格式
def to_numpy(tensor):
    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()

# 构建输入的字典和计算输出结果
ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}
ort_outs = ort_session.run(None, ort_inputs)

# 比较使用PyTorch和ONNX Runtime得出的精度
np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)

print("Exported model has been tested with ONNXRuntime, and the result looks good!")
```

**进行实际预测并可视化**

```python
from PIL import Image
import torchvision.transforms as transforms

# 读取图片
img = Image.open("/cat_224x224.jpg")
# 对图片进行resize操作
resize = transforms.Resize([224, 224])
img = resize(img)

img_ycbcr = img.convert('YCbCr')
img_y, img_cb, img_cr = img_ycbcr.split()

to_tensor = transforms.ToTensor()
img_y = to_tensor(img_y)
img_y.unsqueeze_(0)
# 构建输入的字典并将value转换位array格式
ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}
ort_outs = ort_session.run(None, ort_inputs)
img_out_y = ort_outs[0]
img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L')

# 保存最后得到的图片
final_img = Image.merge(
    "YCbCr", [
        img_out_y,
        img_cb.resize(img_out_y.size, Image.BICUBIC),
        img_cr.resize(img_out_y.size, Image.BICUBIC),
    ]).convert("RGB")

final_img.save("/cat_superres_with_ort.jpg")
```