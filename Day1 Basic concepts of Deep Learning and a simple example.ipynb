{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3966fe6d",
   "metadata": {},
   "source": [
    "# 张量计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da150465",
   "metadata": {},
   "source": [
    "## 定义张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f424a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b76026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8292, 0.9438, 0.8256],\n",
       "        [0.3667, 0.6964, 0.4223],\n",
       "        [0.3804, 0.2910, 0.5408],\n",
       "        [0.8702, 0.4501, 0.3714],\n",
       "        [0.0172, 0.6330, 0.1158]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.rand(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c86a189",
   "metadata": {},
   "source": [
    "## 访问张量\n",
    "张量的下标从0开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0262f534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4223)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#索引访问\n",
    "x[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab249f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8256, 0.4223, 0.5408, 0.3714, 0.1158])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#切片访问\n",
    "x[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c4116e",
   "metadata": {},
   "source": [
    "## 张量运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c33146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3563, 1.2247, 0.9368, 0.8686, 1.5348],\n",
       "        [0.2342, 0.6012, 0.4930, 0.4908, 0.8061],\n",
       "        [0.1255, 0.5973, 0.5102, 0.4113, 0.8121],\n",
       "        [0.2236, 1.0376, 0.5885, 0.5704, 1.0169],\n",
       "        [0.1757, 0.1471, 0.1754, 0.2429, 0.2873]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= torch.rand(5,3)\n",
    "q=x.mm(y.t())\n",
    "q\n",
    "# mm refers to matrix multiply\n",
    "# .t() transform the y matrix from 5*3 to 3*5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71822b8b",
   "metadata": {},
   "source": [
    "## 张量与数组之间的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1c7183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3642,  1.2540,  1.0739],\n",
       "         [ 0.2917,  1.7837, -1.4569]]),\n",
       " array([[1.77638055, 0.23200153, 0.62601601],\n",
       "        [0.19598787, 2.00028063, 0.38753166]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_tensor=torch.randn(2,3)\n",
    "y_numpy=np.random.randn(2,3)\n",
    "x_tensor,y_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2db19853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.36421117,  1.2539915 ,  1.0738758 ],\n",
       "        [ 0.29165778,  1.7836677 , -1.4568555 ]], dtype=float32),\n",
       " tensor([[1.7764, 0.2320, 0.6260],\n",
       "         [0.1960, 2.0003, 0.3875]], dtype=torch.float64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_numpy=x_tensor.numpy()\n",
    "y_tensor=torch.from_numpy(y_numpy)\n",
    "x_numpy,y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a635e34",
   "metadata": {},
   "source": [
    "## GPU上的张量计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d407a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#验证GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a146895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9424, 1.2172, 0.8309],\n",
      "        [1.3381, 0.8395, 0.7665],\n",
      "        [0.7086, 0.4439, 1.1710],\n",
      "        [1.2156, 0.7604, 0.7219],\n",
      "        [0.6599, 0.9042, 1.0194]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#使用 GPU \n",
    "if torch.cuda.is_available():\n",
    "    x=x.cuda()\n",
    "    y=y.cuda()\n",
    "    print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "465ce1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用CPU\n",
    "x=x.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2987fd9",
   "metadata": {},
   "source": [
    "# 动态计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470cf476",
   "metadata": {},
   "source": [
    "## 自动微分变量\n",
    "三个属性：\n",
    "data：伴随自动微分变量的张量，专门储存计算结果\n",
    "grad：.backward() 计算变量的梯度信息，并将叶节点的导数值储存在.grad中\n",
    "grad_fn：回溯箭头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8a2930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#动态计算图实例\n",
    "x=torch.ones(2,2,requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ac634cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x16d20684430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x+2\n",
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ee2ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward0 at 0x16d20684220>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=y*y\n",
    "# * 是对应元素相乘的运算方法\n",
    "z.grad_fn\n",
    "#计算图每增加一次计算，就将相邻的连个计算节点连接在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "543658ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.mean(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a89d4b",
   "metadata": {},
   "source": [
    "## 自动微分与导数计算\n",
    "函数 t(x)=m(x+2)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e823f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9be591ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "tensor([[1.5000, 1.5000],\n",
      "        [1.5000, 1.5000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda_install\\lib\\site-packages\\torch\\_tensor.py:1104: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:475.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "print(z.grad)\n",
    "print(y.grad)\n",
    "print(x.grad)\n",
    "#只有计算图中的叶节点才可以通过.backward()获得梯度信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75502101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[37.1200, 37.1200],\n",
      "        [39.6800, 39.6800]])\n"
     ]
    }
   ],
   "source": [
    "#出现了多次的节点，计算梯度时会为每一个节点计算梯度信息，之后再把同样命名的节点的梯度累加起来\n",
    "s=torch.tensor([[0.01,0.02]],requires_grad=True)\n",
    "x=torch.ones(2,2,requires_grad=True)\n",
    "for i in range(10):\n",
    "    s=s.mm(x)\n",
    "z=torch.mean(s)\n",
    "z.backward()\n",
    "print(s.grad)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919bfbd",
   "metadata": {},
   "source": [
    "# Pytorch 实例：预测房价"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9006b8d",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2ffdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "x= torch.linspace(0,100,100).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "365020fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.0000,   1.0101,   2.0202,   3.0303,   4.0404,   5.0505,   6.0606,\n",
       "          7.0707,   8.0808,   9.0909,  10.1010,  11.1111,  12.1212,  13.1313,\n",
       "         14.1414,  15.1515,  16.1616,  17.1717,  18.1818,  19.1919,  20.2020,\n",
       "         21.2121,  22.2222,  23.2323,  24.2424,  25.2525,  26.2626,  27.2727,\n",
       "         28.2828,  29.2929,  30.3030,  31.3131,  32.3232,  33.3333,  34.3434,\n",
       "         35.3535,  36.3636,  37.3737,  38.3838,  39.3939,  40.4040,  41.4141,\n",
       "         42.4242,  43.4343,  44.4444,  45.4545,  46.4646,  47.4747,  48.4848,\n",
       "         49.4949,  50.5051,  51.5152,  52.5253,  53.5354,  54.5455,  55.5556,\n",
       "         56.5657,  57.5758,  58.5859,  59.5960,  60.6061,  61.6162,  62.6263,\n",
       "         63.6364,  64.6465,  65.6566,  66.6667,  67.6768,  68.6869,  69.6970,\n",
       "         70.7071,  71.7172,  72.7273,  73.7374,  74.7475,  75.7576,  76.7677,\n",
       "         77.7778,  78.7879,  79.7980,  80.8081,  81.8182,  82.8283,  83.8384,\n",
       "         84.8485,  85.8586,  86.8687,  87.8788,  88.8889,  89.8990,  90.9091,\n",
       "         91.9192,  92.9293,  93.9394,  94.9495,  95.9596,  96.9697,  97.9798,\n",
       "         98.9899, 100.0000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9919bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand= torch.randn(100)*10\n",
    "y=x+rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f25e88e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  5.8172,  18.6104,  -1.9580,   8.5302,  11.8980,  14.6372,   9.6438,\n",
       "          8.4861,  -4.3653,  -9.1905,   4.2438,  12.3360,  25.1932,  27.9038,\n",
       "         12.9774,  28.1908,  21.3552,  12.9696,  19.4254,  26.3623,  30.1259,\n",
       "          2.3303,  28.0269,  29.0236,  31.8357,  39.6460,  24.4980,  24.5201,\n",
       "         21.5651,  31.9815,  28.2859,  43.4920,  11.5212,  19.3245,  33.7715,\n",
       "         34.3016,  46.1133,  46.2549,  25.8882,  32.3769,  55.2786,  27.1265,\n",
       "         55.2514,  34.4277,  33.0483,  31.9809,  36.3990,  58.2681,  56.8617,\n",
       "         38.6540,  35.8447,  35.5562,  57.1524,  51.0880,  37.5827,  48.4261,\n",
       "         68.6381,  59.0323,  46.3818,  54.4188,  71.7219,  74.0232,  65.7253,\n",
       "         57.0199,  49.7021,  64.9529,  68.7409,  63.8723,  46.1819,  65.7656,\n",
       "         83.4676,  87.6298,  64.9460,  84.5302,  75.7578,  69.5401,  82.0338,\n",
       "         77.2654,  77.4595,  77.4200,  88.4672,  79.3108,  68.0409,  90.8907,\n",
       "        100.8298,  76.0059,  74.3922,  84.2244,  96.0150, 101.6213,  86.3116,\n",
       "         83.9066,  81.7687,  77.4996, 103.4106,  79.0283,  81.0340, 105.5773,\n",
       "        114.1269, 101.8325])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fc1da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x[:-10]\n",
    "x_test=x[-10 :]\n",
    "y_train=y[:-10]\n",
    "y_test=y[-10 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a331953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.plot(x_train.data.numpy(),y_train.data.numpy(),'o')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8158dd",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a10f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.rand(1,requires_grad=True)\n",
    "b= torch.rand(1,requires_grad=True)\n",
    "learning_rate=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "823e0138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(989.6157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(286.9861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(139.5769, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6509, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(102.1627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.8015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.5159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4396, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4396, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4392, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4392, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4386, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4386, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4385, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4385, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4383, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4383, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4377, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4377, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4374, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4374, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4369, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4369, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4367, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4367, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4367, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4365, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4365, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4359, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4359, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4355, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4355, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4355, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4353, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4353, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4353, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4349, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4349, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4345, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4345, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4342, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4342, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4342, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4340, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4340, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4334, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4334, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4332, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4332, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4320, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4320, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4315, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4315, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4309, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4309, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4306, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4306, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4306, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4304, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4304, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4300, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4300, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4297, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4297, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4289, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4289, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4288, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4288, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4288, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4284, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4284, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4282, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4282, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4280, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4280, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4271, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4271, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4271, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4268, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4268, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4263, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4263, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4263, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4257, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4257, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4257, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4254, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4254, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4244, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4244, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4242, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4242, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4240, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4240, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4240, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4237, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4237, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4235, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4235, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4233, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4233, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4233, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4227, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4227, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4227, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4221, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4221, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4221, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4220, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4220, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4218, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4218, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4213, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4213, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4213, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4210, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4210, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4204, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4204, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4199, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4199, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4199, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4197, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4197, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4194, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4194, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4192, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4192, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4189, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4189, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4189, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4188, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4188, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4187, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(100.4187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4184, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4184, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4184, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4182, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4182, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4172, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4172, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4166, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4166, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4166, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4163, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4163, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4158, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4158, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4158, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4155, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4155, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4150, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4150, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4149, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4149, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4149, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4144, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4144, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4144, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4142, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4142, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4142, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4139, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4139, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4133, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4133, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4133, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4129, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4129, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4129, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4124, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4124, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4121, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4121, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4121, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4117, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(100.4117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4106, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4106, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4103, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4103, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4095, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4095, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4093, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4093, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4093, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4089, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4089, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4089, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4082, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4082, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4079, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4079, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4072, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4072, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4072, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4068, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4068, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4068, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4065, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4065, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4057, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4057, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4053, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4053, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4053, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4051, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4051, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4047, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4047, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4047, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4045, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4045, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4044, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4044, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4044, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4042, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4042, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4026, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4026, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4019, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4019, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4017, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4017, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(100.4011, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    predictions= a.expand_as(x_train)*x_train+b.expand_as(x_train)\n",
    "    loss=torch.mean((predictions-y_train)**2)\n",
    "    print('loss:',loss)\n",
    "    loss.backward()\n",
    "    a.data.add_(-learning_rate*a.grad.data)\n",
    "    b.data.add_(-learning_rate*b.grad.data)\n",
    "    a.grad.data.zero_()\n",
    "    b.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054fa34",
   "metadata": {},
   "source": [
    "### 上述步骤技术细节\n",
    "计算predictions时，对a，b进行了扩充维度\n",
    "只能对自动微分变量进行数值更新，所以更新a.data\n",
    "某个函数后面增加了_，表明要用这个函数额计算结果替换当前的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04e45d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# x_data=x_train.data.numpy()\n",
    "# plt.figure()\n",
    "# xplot,=plt.plot(x_data,y_train.data.numpy())\n",
    "# yplot =plt.plot(x_data,a.data.numpy()*x_data+b.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c588e12",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84fa4f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([89.4654, 90.4550, 91.4446, 92.4342, 93.4238, 94.4134, 95.4031, 96.3927,\n",
       "        97.3823, 98.3719], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=a.expand_as(x_test)*x_test+b.expand_as(x_test)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
